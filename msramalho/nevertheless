from __future__ import division
import sys
import os
import json
import random
import operator
import _thread as thread
from timeit import default_timer
from itertools import product
from copy import deepcopy
from collections import defaultdict
from random import choice
from math import log, sqrt
import datetime
import numpy as np
from time import sleep
# from threading import Lock
import signal

import multipaint

# function names camelCase -  properties names snake_case

#---------------------------------------------UTILS

random.seed()


def p(string=""):  # pragma: no cover
    print(string, file=sys.stderr)

# https://gist.github.com/cgoldberg/2942781


class Timer(object):  # pragma: no cover
    def __init__(self, name="", verbose=True):
        self.name = " for %s" % name
        self.verbose = verbose
        self.timer = default_timer

    def __enter__(self):
        self.start = self.timer()
        return self

    def __exit__(self, *args):
        end = self.timer()
        self.elapsed_secs = end - self.start
        self.elapsed = self.elapsed_secs * 1000  # millisecs
        if self.verbose:
            p("elapsed time%s: %f ms, %f s" % (self.name, self.elapsed, self.elapsed_secs))


#---------------------------------------------STATE
# height = number of rows
# width  = number of columns
# player position: {x: , y: } where x is the row (height) and y is the column (width)

possible_directions = [
    np.array([-1, -1]), np.array([-1,  0]), np.array([-1,  1]),
    np.array([0, -1]), np.array([0,  1]),
    np.array([1, -1]), np.array([1,  0]), np.array([1,  1])
]


class State:
        # me(my id), turns_left, rows, columns, players (dict of id=>(x,y)), board(ndarray), previous_actions (only if specified)
    def __init__(self, s, me, previous_actions=False):
        self.turns_left = int(s["turns_left"])
        self.rows = int(s["height"])
        self.columns = int(s["width"])

        # get numpy board from matrix of strings, must come before self.players due to self.player_ids
        self.loadBoard(s["colors"], s["player_positions"].keys())

        self.me = self.player_ids[me]

        # convert the json into a dict of {player1Name: (x, y), ...}
        self.players = {self.player_ids[p]: np.array([s["player_positions"][p][0], s["player_positions"][p][1]])
                        for p in s["player_positions"].keys()}

        # optional (because this may be irrelevant and occupies a lot of space)
        # self.previous_actions = s["previous_actions"] if previous_actions else []
        # if previous_actions:
        if len(s["previous_actions"]) > 0:
            self.last_move = s["previous_actions"][-1]
        else:
            self.last_move = None

        # by default the scores are only loaded on loadPlayerScores
        self.scores = {}
        self.moves = None

    # generate board - (-1 is for empty, 0 is for objects, 1 to \inf is for players' colors)
    def loadBoard(self, colors, player_names):
        self.player_ids = {}  # {-1: "neutral", 0: "object"}  # dict mapping player ids into names, useful to know a player from its number in the board
        temp = np.array(colors)
        condlist = [temp == None]
        choicelist = [-1]
        for i, player in enumerate(player_names):
            condlist.append(temp == player)
            choicelist.append(i + 1)
            self.player_ids[player] = i + 1  # update the player_ids dict
        self.board = np.select(condlist, choicelist)

    # given a game state (self) and a player id, not name, get the valid moves for that player
    def getValidMovesForPlayer(self, player):
        pos = self.players[player]  # (line, column) or (x, y)
        valid = []
        for d in possible_directions:
            if self.insideBoardAfterMove(pos, d):
                # t = d.tolist()  # temp, just so operation happens only once
                valid.extend([{"type": "shoot", "direction": d}, {"type": "walk", "direction": d}])
        return valid

    # return True if the position p, after moving in direction d, is inside the board
    def insideBoard(self, p):
        return (0 <= p[0] and p[0] < self.rows) and (0 <= p[1] and p[1] < self.columns)

    # return True if the position p, after moving in direction d, is inside the board
    def insideBoardAfterMove(self, pos, direction):
        p = pos + direction
        return self.insideBoard(p)

    # load self.scores with a dict of {player=>score}
    def loadPlayerScores(self):
        s1, s2 = np.unique(self.board, return_counts=True)  # unique, counts
        self.scores = dict(zip(s1, s2))

    # get all the combinations of moves for all the players, for N players -> max is 16^N (256 for 2 players)
    def getAllMoveCombinations(self):
        return list(product(*[self.getValidMovesForPlayer(p) for p in self.players.keys()]))

    # given a position, a color, and a direction, count cells of the same color in the opposite direction
    def shotBackCount(self, pos, direction, color):
        res = 0
        bp = pos - direction  # back pos
        while self.insideBoard(bp) and self.board[bp[0], bp[1]] == color:
            bp -= direction  # back pos
            res += 1
        return max(res, 1)  # minimum shot size is 1

    # given a position, a direction, and the max value for it, calculate the distance to the edges [0---pos---end]
    def distanceToEnd(self, pos, direction, end):
        if direction == -1:  # backwards is the distance to the start, pos - 0
            return pos
        elif direction == 1:  # forwards is the distance to the end, end - pos
            return end - pos
        else:  # 0 means it stays put, return more than the max, in any direction
            return self.columns + self.rows

    # given a position and a direction return the shot range
    # minimum of the distance in each of the axis to the border
    def shotRange(self, pos, d):
        # had to take 1 from the rows and columns because it is zero indexed
        return min(self.distanceToEnd(pos[0], d[0], self.rows - 1), self.distanceToEnd(pos[1], d[1], self.columns - 1))

    # given a player and a direction get the range of the shot (max between shot load and board limits)
    def playerShotRange(self, player, d):
        return min(self.shotBackCount(self.players[player], d, player), self.shotRange(self.players[player], d))

    # given a tuple of moves for the players index is 1 to n (can use self.player_ids)
    # apply those moves and return a new state
    # if load scores is True then loadPlayerScores is called
    def getNewState(self, actions, load_scores=True):
        # create a copy of the current state
        state = deepcopy(self)
        # otherwise singleton does not work, because the moves were only valid for the previous state
        state.moves = None
        state.scores = {}
        state.turns_left -= 1

        # ---------1. all movement actions are applied

        # 1.0 create useful variables
        # dict of playerIndex: (moveUndone, move) if action is walk
        bot_moves = {i + 1: [False, m] for i, m in enumerate(actions) if m["type"] == "walk"}

        # 1.1 each avatar is placed in its new position
        for id, (_, action) in bot_moves.items():
            state.players[id] += action["direction"]  # sum pos with dir to give new pos

        # 1.2 while there is a square with two or more avatars in it, actions from all avatars in the square are undone
        overlaping = True
        while overlaping:
            overlaping = False
            move_squares = defaultdict(list)
            for pl in state.players:
                move_squares[str(state.players[pl])].append(pl)  # create or extend
            for square, bots in move_squares.items():
                if len(bots) > 1:
                    overlaping = True
                    for b in bots[:]:
                        if b in bot_moves and bot_moves[b][0] == False:
                            bot_moves[b][0] = True  # set undone as True
                            bots.remove(b)
                            state.players[b] -= bot_moves[b][1]["direction"]  # calculate the old position

        # 1.3 paint the squares occupied by all the avatars
        bot_squares = set()  # dict of cell -> bot_id_in_that_cell
        for player_id, pos in state.players.items():
            state.board[pos[0], pos[1]] = player_id  # update the board with the new positions
            bot_squares.add((pos[0], pos[1]))  # tuple and not string for 2.3.3

        # ---------2 all shooting actions are applied

        # 2.1 each action's range is calculated
        # dict of playerIndex: [range, pos, dir, active] if action is shoot
        bot_shots = {i + 1: [self.playerShotRange(i + 1, m["direction"]), self.players[i + 1], m["direction"], True] for i, m in enumerate(actions) if m["type"] == "shoot"}

        # 2.2 consider each shot a projectile that moves one square at a time, starting at the avatar's position
        # 2.3 while there are active shots:
        activeShots = len(bot_shots)
        k = 1  # number of iterations
        paintedInThisTurn = set()  # list of squares that were painted in this turn
        while activeShots > 0:
            # 2.3.1 advance all shots one square
            squares = defaultdict(list)  # dict of cell -> [bot_ids]
            for id, [r, pos, d, active] in bot_shots.items():
                if active:
                    # 2.3.4 disable any shots that have reached their maximum range
                    if k == r + 1:
                        bot_shots[id][3] = False  # set inactive
                        activeShots -= 1  # update active count
                    elif k <= r:  # must be active and within range
                        # TODO: ver porque é que isto estoura às vezes -> resposta o d, actions[i]["direction"] vem como não np.array, mas ainda não percebi pq
                        try:
                            nPos = pos + k * d  # new position
                        except ValueError as err:
                            nPos = pos + k * np.array(d)
                            # p("nPos = %s, pos = %s, k = %s, d = %s, bot_shots[%s] = %s" % (nPos, pos, k, d, id, bot_shots[id]))
                            # p(err)
                        squares[(nPos[0], nPos[1])].append(id)  # use tuple as dict key instead of str for 2.3.3
            # 2.3.2 any shots that share a square with other shots or with any avatars, or that are in squares painted in this turn, are disabled
            for square, bots in squares.copy().items():  # copy because the original will be changed
                if len(bots) > 1 or square in bot_squares or square in paintedInThisTurn:
                    squares.pop(square)  # remove this shot from the future painted shots
                    for b in bots[:]:
                        bot_shots[b][3] = False  # disable this shot
                        activeShots -= 1  # update active count

            # 2.3.3 paint the squares of the remaining active shots
            for l, c in squares:
                state.board[l, c] = squares[(l, c)][0]
                paintedInThisTurn.add((l, c))

            k += 1

        if load_scores:
            state.loadPlayerScores()

        return state

    # given the current game state evaluate the value of the board
    def getHeuristic(self):
        total_squares = self.rows * self.columns
        my_squares = self.scores[self.me]
        empty_squares = self.scores[-1]  # ignore objects
        opponents_squares = total_squares - my_squares - empty_squares
        return (my_squares - opponents_squares) / total_squares

    # given a history of states, return the winning player
    def getWinner(self):
        avatar_scores = {k: v for k, v in self.scores.items() if k > 0}
        v = list(avatar_scores.values())
        k = list(avatar_scores.keys())
        winner = max(v)
        if v.count(winner) > 1:  # draw
            return False
        return k[v.index(winner)]

    # return true if i win at the current state
    def iWon(self):
        return self.me == self.getWinner()

    # singleton to return a random, not visited state (fails if none left) -> check before -> expand
    def getRandomMove(self):
        return self.moves.pop()

    # save all the valid moves singleton style
    def loadAllMoves(self):
        if self.moves != None:
            return
        self.moves = self.getAllMoveCombinations()
        random.shuffle(self.moves)

    def __repr__(self):
        return "turns_left: %d\nplayers: %s,\nboard: %s" % (self.turns_left, self.players, self.board)


##################################################################

ROOT = None  # the search tree root


# very important: Node.state.moves holds all the moves that have not been expanded
# Node.children holds all the Nodes resulting from poping a move from Node.state.moves
class Node(object):
    MAX_DEPTH = 5  # max depth for the simulation
    C = 1.4  # learning rate
    SAMPLES = 1  # number of samples to make for each random_simulation
    ID = 0

    def __init__(self, state, parent=None, move=None):
        self.wins = 0
        self.plays = 0
        self.parent = parent
        self.children = {}
        self.state = state
        self.move = move  # the move made that led to this state
        self.expanded = False
        self.state.loadAllMoves()  # load all the possible moves only once per Node
        self.heuristic = 0  # node value evaluated by heuristic function for the board
        # debug stuff
        self.id = Node.ID
        Node.ID += 1
        # backprop if applicable
        if len(self.state.scores) > 0:
            self.backprop(self.state.iWon(), self.state.getHeuristic())

    # TODO: use this, but be careful not to delete the new root and its descendants
    def __del__(self):
        for child in list(self.children.keys()):#[:]:
            if child != ROOT:
                del self.children[child]

    # once more information is received, make the new root of the children of the current root
    # TODO: if we run into space problems: delete nodes that are not the right child
    def makeChildNewRoot(new_state):
        global ROOT
        old_root = ROOT

        # find the child matching the move made
        move = tuple(new_state.last_move.values())
        for action in move:
            action["direction"] = np.array(action["direction"])
        move = str(move)
        if move in old_root.children.keys():  # if every player made a move, start NEH-MCTS
            ROOT = old_root.children[move]
        else:  # the next node is not in the tree, so has to restart empty handed MCTS
            ROOT = Node(new_state)
        del old_root

    # get the best move for the explored states from the current Node
    def getNextMove(self):
        if len(self.children) == 0:
            best = self.state.getRandomMove()
        else:
            best = self.getBestValueChild()  # my best child
            best = best.move
        return best[self.state.me - 1]  # my move in that child, 0 indexed, IDS are not

    # get the value (wins/plays ratio) for this node
    def getValue(self):
        return self.wins / self.plays

    # get the child with the highest Value
    # MUST be expanded, otherwise max fails for empty list
    def getBestValueChild(self):
        # return max(self.children.values(), key=lambda c: c.getValue())
        return max(self.children.values(), key=lambda c: c.heuristic)

    # get the child with the highest Value
    # MUST be expanded, otherwise max fails for empty list
    def getBestUCTChild(self):
        return max(self.children.values(), key=lambda c: c.getUCT())

    # get the UCT value for the current node (the root node will crash due to no parent)
    def getUCT(self):
        # TODO remove this after testing because it crashes for ROOT id 0
        if self.parent is None:
            return -1
        return self.getValue() + Node.C * sqrt(log(self.parent.plays) / self.plays)

    # if this node is expanded keep on selection until a not expanded node is found
    def selection(self):
        # p("Selection for " + str(self) + "\n from these: " + str(self.children) + "\n i choose: ")
        if self.expanded:
            # p(self.getBestUCTChild())
            self.getBestUCTChild().selection()
        elif len(self.state.moves) > 0:
            # p("NONE -> i am simulating")
            self.run_simulation()

    # expand an unexpanded node -> produce all children
    # TODO: improve this to avoid generating all children
    def expand(self):
        self.expanded = True
        for move in self.state.moves:
            # with Timer("get new state for move %s of node %d" % (move, self.id)) as t:
            self.children[str(move)] = Node(self.state.getNewState(move), self, move)

    def updateHeuristic(self, child_heuristic):
        self.heuristic = max(child_heuristic, self.heuristic)
        return self.heuristic

    # after a simulation, save the result and propagate it back to its parents recursively
    def backprop(self, victory, child_heuristic):
        self.plays += 1
        if victory:
            self.wins += 1
        if self.parent:
            self.parent.backprop(victory, self.updateHeuristic(child_heuristic))

    # run a NEW simulation for the current node
    def run_simulation(self):
        # either simulate for turns_left or MAX_DEPTH
        node = self  # current node
        # for j in range(Node.SAMPLES):  # number of samples for each leaf node undergoing MC simulations
        for i in range(min(self.state.turns_left, Node.MAX_DEPTH + 1)):  # depth of the simulation
            random_move = node.state.getRandomMove()  # get a random move from the node
            node = Node(node.state.getNewState(random_move), node, random_move)

    # start mcts -> if expanded, select best child and run recursively
    # if not expanded -> expand and run_simulation
    def mcts(self):
        if self.expanded:  # TODO: can also expand after a given number of plays (THRESHOLD)
            self.selection()
        else:
            self.expand()

    def __repr__(self):
        if self.plays > 0:
            return "NODE %d: wins/plays = %d/%d = %.1f, value = %d, UCT: %.2f, children = %d, unexplored = %d" % (self.id, self.wins, self.plays, (100 * self.wins / self.plays), self.getValue(), self.getUCT(), len(self.children), len(self.state.moves))
        else:
            return "NODE %d: wins/plays = %d/%d, children = %d, unexplored = %d" % (self.id, self.wins, self.plays, len(self.children), len(self.state.moves))


def concurrent_mcts():
    global ROOT
    iterations = 0
    while ROOT is None:
        pass
    while True:
        ROOT.mcts()
        # p("Iteration %d complete - ROOT is %d" % (iterations, ROOT.id))
        iterations += 1

##################################################################


# lock = Lock()


# def handler(signum, frame):
#     lock.release()
#     p("end of time")

# signal.signal(signal.SIGALRM, handler)

class Bot(object):

    def __init__(self, player_id):
        self.player_id = player_id
        thread.start_new_thread(concurrent_mcts, ())

    def load_root(self):
        global ROOT

        if ROOT is None:
            ROOT = Node(self.state)
        else:
            Node.makeChildNewRoot(self.state)

    # make this move last as long as possible
    def smart_sleep(self, start):
        max_sleep = 0.46 - (default_timer() - start)
        sleep(max_sleep)
        # while (default_timer() - start) < 0.45:
            # sleep(0.01)
        # p("start = %.4fms, max_sleep = %.4fms, total: %.4fms, " % (start / 1000, max_sleep, (default_timer() - start)))
        # p("WOKEN UP FROM SLEEP")

    def clearChoice(self, c):  # pragma: no cover
        c["direction"] = c["direction"].tolist()
        return c

    def next_move(self, s):  # pragma: no cover
        # with Timer("next_move"):
        start = default_timer()
        self.state = State(s, self.player_id)  # tipically 0.1 ms
        self.load_root()
        self.smart_sleep(start)
        return self.clearChoice(ROOT.getNextMove())


if __name__ == "__main__":  # pragma: no cover
    multipaint.run(Bot)